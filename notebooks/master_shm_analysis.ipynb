{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHM Heavy Equipment Price Prediction: Master Analysis\n",
    "\n",
    "**Comprehensive Consulting Deliverable**\n",
    "\n",
    "---\n",
    "\n",
    "**Client:** SHM (Secondhand Machinery Dealer)  \n",
    "**Challenge:** Replace retiring expert's pricing knowledge with ML model  \n",
    "**Dataset:** 412,698 heavy equipment auction records (1989-2012)  \n",
    "**Analysis Date:** August 22, 2025  \n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "### Key Findings\n",
    "- **Model Performance**: RandomForest achieves 42.7% accuracy within ±15% tolerance (RMSLE: 0.299)\n",
    "- **Business Assessment**: Requires improvement before production deployment\n",
    "- **Critical Issues**: 82% missing usage data, market volatility during 2008-2010 crisis\n",
    "- **Geographic Variations**: 80% price differences across states (South Dakota $43,907 vs Indiana $24,400)\n",
    "- **Recommendation**: Implement feature engineering improvements and additional data collection\n",
    "\n",
    "### Business Impact\n",
    "Current model performance indicates significant improvement needed before production deployment. While the foundation is solid, achieving the target 80% accuracy within ±15% requires strategic enhancement of feature engineering and data quality.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Load the dataset\n",
    "data_path = '../data/raw/Bit_SHM_data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Date Range: {df['SaleDate'].min()} to {df['SaleDate'].max()}\")\n",
    "print(f\"Price Range: ${df['SalePrice'].min():,.0f} to ${df['SalePrice'].max():,.0f}\")\n",
    "print(f\"Average Price: ${df['SalePrice'].mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Critical Business Findings\n",
    "\n",
    "Based on comprehensive analysis, we identified 5 critical business challenges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load business findings\n",
    "with open('../outputs/findings/business_findings.json', 'r') as f:\n",
    "    findings = json.load(f)\n",
    "\n",
    "print(\"=== CRITICAL BUSINESS FINDINGS ===\")\n",
    "print(f\"Analysis Date: {findings['timestamp']}\")\n",
    "print(f\"Total Records: {findings['dataset_info']['total_records']:,}\")\n",
    "print(f\"Average Price: ${findings['dataset_info']['average_price']:,.0f}\")\n",
    "print(\"\\n--- Key Findings ---\")\n",
    "\n",
    "for i, finding in enumerate(findings['key_findings'][:5], 1):\n",
    "    print(f\"\\n{i}. {finding['title']}\")\n",
    "    print(f\"   Finding: {finding['finding']}\")\n",
    "    print(f\"   Impact: {finding['business_impact']}\")\n",
    "    print(f\"   Action: {finding['recommendation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding 1: Critical Missing Usage Data (82%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze missing usage data\n",
    "machine_hours = df['MachineHoursCurrentMeter']\n",
    "missing_hours = machine_hours.isna().sum() + (machine_hours == 0).sum()\n",
    "missing_pct = (missing_hours / len(df)) * 100\n",
    "\n",
    "print(f\"Missing/Zero Machine Hours: {missing_hours:,} records ({missing_pct:.1f}%)\")\n",
    "print(f\"Records with Valid Hours: {len(df) - missing_hours:,}\")\n",
    "print(f\"Business Impact: Prevents accurate depreciation modeling for ${(df['SalePrice'].sum() * missing_pct/100):,.0f} in equipment value\")\n",
    "\n",
    "# Visualize the impact\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Usage data availability\n",
    "usage_data = ['Valid Hours', 'Missing/Zero Hours']\n",
    "usage_counts = [len(df) - missing_hours, missing_hours]\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "\n",
    "ax1.pie(usage_counts, labels=usage_data, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "ax1.set_title('Machine Hours Data Availability\\n(82% Missing/Zero)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Price distribution by usage data availability\n",
    "valid_hours_prices = df[machine_hours > 0]['SalePrice']\n",
    "missing_hours_prices = df[(machine_hours.isna()) | (machine_hours == 0)]['SalePrice']\n",
    "\n",
    "ax2.hist(valid_hours_prices, bins=50, alpha=0.7, label=f'Valid Hours (n={len(valid_hours_prices):,})', color='#2ecc71')\n",
    "ax2.hist(missing_hours_prices, bins=50, alpha=0.7, label=f'Missing Hours (n={len(missing_hours_prices):,})', color='#e74c3c')\n",
    "ax2.set_xlabel('Sale Price ($)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Price Distribution by Usage Data Availability', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAverage Price - Valid Hours: ${valid_hours_prices.mean():,.0f}\")\n",
    "print(f\"Average Price - Missing Hours: ${missing_hours_prices.mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding 2: Market Volatility (2008-2010 Crisis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze temporal patterns and market volatility\n",
    "df['SaleDate'] = pd.to_datetime(df['SaleDate'])\n",
    "df['SaleYear'] = df['SaleDate'].dt.year\n",
    "\n",
    "# Annual price statistics\n",
    "annual_stats = df.groupby('SaleYear')['SalePrice'].agg(['mean', 'median', 'count', 'std']).reset_index()\n",
    "\n",
    "# Identify crisis period\n",
    "crisis_years = [2008, 2009, 2010]\n",
    "pre_crisis = annual_stats[annual_stats['SaleYear'] < 2008]['mean'].mean()\n",
    "crisis_period = annual_stats[annual_stats['SaleYear'].isin(crisis_years)]['mean'].mean()\n",
    "post_crisis = annual_stats[annual_stats['SaleYear'] > 2010]['mean'].mean()\n",
    "\n",
    "print(f\"Pre-Crisis Average (1989-2007): ${pre_crisis:,.0f}\")\n",
    "print(f\"Crisis Period Average (2008-2010): ${crisis_period:,.0f}\")\n",
    "print(f\"Post-Crisis Average (2011-2012): ${post_crisis:,.0f}\")\n",
    "print(f\"Crisis Impact: {((crisis_period - pre_crisis) / pre_crisis * 100):+.1f}% change\")\n",
    "\n",
    "# Visualize temporal trends\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))\n",
    "\n",
    "# Price trends\n",
    "ax1.plot(annual_stats['SaleYear'], annual_stats['mean'], marker='o', linewidth=2, markersize=6, color='#3498db')\n",
    "ax1.fill_between([2008, 2010], ax1.get_ylim()[0], ax1.get_ylim()[1], alpha=0.2, color='red', label='Crisis Period')\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Average Sale Price ($)')\n",
    "ax1.set_title('Annual Average Sale Prices with Crisis Period Highlighted', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "# Volume trends\n",
    "ax2.bar(annual_stats['SaleYear'], annual_stats['count'], color='#95a5a6', alpha=0.7)\n",
    "ax2.set_xlabel('Year')\n",
    "ax2.set_ylabel('Number of Sales')\n",
    "ax2.set_title('Annual Sales Volume', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight crisis years\n",
    "for year in crisis_years:\n",
    "    crisis_count = annual_stats[annual_stats['SaleYear'] == year]['count'].iloc[0]\n",
    "    ax2.bar(year, crisis_count, color='red', alpha=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding 3: Geographic Price Disparities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze geographic price variations\n",
    "geo_analysis = findings['comprehensive_analysis']['geographic_analysis']\n",
    "\n",
    "# Extract state statistics\n",
    "state_means = pd.DataFrame.from_dict(geo_analysis['state_statistics']['mean'], orient='index', columns=['AvgPrice'])\n",
    "state_counts = pd.DataFrame.from_dict(geo_analysis['state_statistics']['count'], orient='index', columns=['Count'])\n",
    "state_data = state_means.join(state_counts)\n",
    "\n",
    "# Filter states with sufficient data (>500 records)\n",
    "significant_states = state_data[state_data['Count'] > 500].sort_values('AvgPrice', ascending=False)\n",
    "\n",
    "print(f\"States Analyzed: {len(state_data)}\")\n",
    "print(f\"States with >500 records: {len(significant_states)}\")\n",
    "print(f\"\\nTop 5 Highest Average Prices:\")\n",
    "for state, row in significant_states.head().iterrows():\n",
    "    print(f\"  {state}: ${row['AvgPrice']:,.0f} ({row['Count']:,} sales)\")\n",
    "\n",
    "print(f\"\\nBottom 5 Lowest Average Prices:\")\n",
    "for state, row in significant_states.tail().iterrows():\n",
    "    print(f\"  {state}: ${row['AvgPrice']:,.0f} ({row['Count']:,} sales)\")\n",
    "\n",
    "# Calculate price disparity\n",
    "highest_price = significant_states['AvgPrice'].max()\n",
    "lowest_price = significant_states['AvgPrice'].min()\n",
    "disparity = ((highest_price - lowest_price) / lowest_price) * 100\n",
    "\n",
    "print(f\"\\nPrice Disparity Analysis:\")\n",
    "print(f\"Highest: ${highest_price:,.0f}\")\n",
    "print(f\"Lowest: ${lowest_price:,.0f}\")\n",
    "print(f\"Disparity: {disparity:.1f}% difference\")\n",
    "\n",
    "# Visualize geographic variations\n",
    "plt.figure(figsize=(16, 8))\n",
    "top_15_states = significant_states.head(15)\n",
    "\n",
    "bars = plt.bar(range(len(top_15_states)), top_15_states['AvgPrice'], \n",
    "               color=['#e74c3c' if price > 35000 else '#f39c12' if price > 30000 else '#2ecc71' \n",
    "                      for price in top_15_states['AvgPrice']])\n",
    "\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Average Sale Price ($)')\n",
    "plt.title('Geographic Price Variations - Top 15 States by Average Price\\n(States with >500 sales)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(len(top_15_states)), top_15_states.index, rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, price) in enumerate(zip(bars, top_15_states['AvgPrice'])):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 500, \n",
    "             f'${price:,.0f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Development and Training\n",
    "\n",
    "### Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and demonstrate the actual data preprocessing pipeline\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_loader import SHMDataLoader\n",
    "from models import EquipmentPricePredictor\n",
    "from evaluation import ModelEvaluator\n",
    "\n",
    "# Initialize data loader\n",
    "loader = SHMDataLoader()\n",
    "data = loader.load_and_preprocess(data_path)\n",
    "\n",
    "print(\"=== DATA PREPROCESSING COMPLETE ===\")\n",
    "print(f\"Original columns: {df.shape[1]}\")\n",
    "print(f\"Processed columns: {data.shape[1]}\")\n",
    "print(f\"Records processed: {data.shape[0]:,}\")\n",
    "\n",
    "# Show key engineered features\n",
    "engineered_features = ['age_years', 'log1p_hours', 'hours_per_year', 'sale_month', 'sale_quarter']\n",
    "available_features = [f for f in engineered_features if f in data.columns]\n",
    "\n",
    "print(f\"\\nKey Engineered Features: {available_features}\")\n",
    "if available_features:\n",
    "    print(data[available_features].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training with Temporal Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load actual model results\n",
    "with open('../outputs/models/honest_metrics_20250822_005248.json', 'r') as f:\n",
    "    model_results = json.load(f)\n",
    "\n",
    "print(\"=== ACTUAL MODEL PERFORMANCE ===\")\n",
    "print(f\"Training Strategy: {model_results['strategy']}\")\n",
    "print(f\"Data Leakage Protection: {model_results['leakage_features_removed']}\")\n",
    "print(f\"Timestamp: {model_results['timestamp']}\")\n",
    "\n",
    "# Display model comparison\n",
    "models_performance = []\n",
    "for model_name, metrics in model_results['models'].items():\n",
    "    test_metrics = metrics['test_metrics']\n",
    "    models_performance.append({\n",
    "        'Model': model_name,\n",
    "        'RMSLE': test_metrics['rmsle'],\n",
    "        'MAPE': test_metrics['mape'],\n",
    "        'R²': test_metrics['r2'],\n",
    "        'Within_15%': test_metrics['within_15_pct'],\n",
    "        'MAE': test_metrics['mae'],\n",
    "        'Training_Time': metrics['training_time']\n",
    "    })\n",
    "\n",
    "performance_df = pd.DataFrame(models_performance)\n",
    "print(\"\\n=== MODEL COMPARISON ===\")\n",
    "print(performance_df.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive model performance visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Model Comparison - Key Metrics\n",
    "metrics = ['RMSLE', 'MAPE', 'Within_15%']\n",
    "rf_values = [performance_df[performance_df['Model'] == 'RandomForest'][metric].iloc[0] for metric in metrics]\n",
    "cb_values = [performance_df[performance_df['Model'] == 'CatBoost'][metric].iloc[0] for metric in metrics]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(x - width/2, rf_values, width, label='RandomForest', color='#3498db', alpha=0.8)\n",
    "ax1.bar(x + width/2, cb_values, width, label='CatBoost', color='#e74c3c', alpha=0.8)\n",
    "ax1.set_xlabel('Metrics')\n",
    "ax1.set_ylabel('Value')\n",
    "ax1.set_title('Model Performance Comparison', fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(metrics)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (rf_val, cb_val) in enumerate(zip(rf_values, cb_values)):\n",
    "    ax1.text(i - width/2, rf_val + 0.01, f'{rf_val:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    ax1.text(i + width/2, cb_val + 0.01, f'{cb_val:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. Accuracy Tolerance Analysis\n",
    "tolerance_levels = ['within_10_pct', 'within_15_pct', 'within_25_pct']\n",
    "tolerance_labels = ['±10%', '±15%', '±25%']\n",
    "\n",
    "rf_test = model_results['models']['RandomForest']['test_metrics']\n",
    "cb_test = model_results['models']['CatBoost']['test_metrics']\n",
    "\n",
    "rf_tolerances = [rf_test[tol] for tol in tolerance_levels]\n",
    "cb_tolerances = [cb_test[tol] for tol in tolerance_levels]\n",
    "\n",
    "x2 = np.arange(len(tolerance_labels))\n",
    "ax2.bar(x2 - width/2, rf_tolerances, width, label='RandomForest', color='#3498db', alpha=0.8)\n",
    "ax2.bar(x2 + width/2, cb_tolerances, width, label='CatBoost', color='#e74c3c', alpha=0.8)\n",
    "ax2.set_xlabel('Tolerance Level')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Accuracy within Price Tolerance Bands', fontweight='bold')\n",
    "ax2.set_xticks(x2)\n",
    "ax2.set_xticklabels(tolerance_labels)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=80, color='green', linestyle='--', alpha=0.7, label='Target (80%)')\n",
    "\n",
    "# Add value labels\n",
    "for i, (rf_val, cb_val) in enumerate(zip(rf_tolerances, cb_tolerances)):\n",
    "    ax2.text(i - width/2, rf_val + 1, f'{rf_val:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "    ax2.text(i + width/2, cb_val + 1, f'{cb_val:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 3. Business Assessment Summary\n",
    "assessment = model_results['business_assessment']\n",
    "models = list(assessment['individual_assessments'].keys())\n",
    "performance_scores = [assessment['individual_assessments'][model]['test_within_15_pct'] for model in models]\n",
    "target_score = 80  # Business target\n",
    "\n",
    "colors = ['#e74c3c' if score < 50 else '#f39c12' if score < 70 else '#2ecc71' for score in performance_scores]\n",
    "bars = ax3.bar(models, performance_scores, color=colors, alpha=0.8)\n",
    "ax3.axhline(y=target_score, color='green', linestyle='--', linewidth=2, label=f'Business Target ({target_score}%)')\n",
    "ax3.set_xlabel('Model')\n",
    "ax3.set_ylabel('Accuracy within ±15% (%)')\n",
    "ax3.set_title('Business Readiness Assessment', fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Add status labels\n",
    "for bar, score, model in zip(bars, performance_scores, models):\n",
    "    status = \"NEEDS IMPROVEMENT\" if score < 70 else \"APPROACHING TARGET\" if score < 80 else \"TARGET ACHIEVED\"\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
    "             f'{score:.1f}%\\n{status}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# 4. Training Time vs Performance\n",
    "training_times = [model_results['models'][model]['training_time'] for model in models]\n",
    "scatter = ax4.scatter(training_times, performance_scores, s=200, alpha=0.7, c=colors)\n",
    "\n",
    "for model, time, score in zip(models, training_times, performance_scores):\n",
    "    ax4.annotate(model, (time, score), xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "\n",
    "ax4.set_xlabel('Training Time (seconds)')\n",
    "ax4.set_ylabel('Accuracy within ±15% (%)')\n",
    "ax4.set_title('Training Efficiency Analysis', fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.axhline(y=target_score, color='green', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print business assessment\n",
    "print(\"\\n=== BUSINESS ASSESSMENT ===\")\n",
    "best_model = assessment['best_model']\n",
    "best_assessment = assessment['individual_assessments'][best_model]\n",
    "\n",
    "print(f\"Best Performing Model: {best_model}\")\n",
    "print(f\"Test Accuracy (±15%): {best_assessment['test_within_15_pct']:.1f}%\")\n",
    "print(f\"RMSLE: {best_assessment['test_rmsle']:.3f}\")\n",
    "print(f\"Business Ready: {best_assessment['business_ready']}\")\n",
    "print(f\"Risk Level: {best_assessment['risk_level']}\")\n",
    "print(f\"Recommendation: {best_assessment['recommendation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Business Impact Analysis\n",
    "\n",
    "### Current Model Limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze business impact of current model performance\n",
    "best_model_performance = performance_df[performance_df['Model'] == 'RandomForest'].iloc[0]\n",
    "\n",
    "current_accuracy = best_model_performance['Within_15%']\n",
    "target_accuracy = 80.0\n",
    "improvement_needed = target_accuracy - current_accuracy\n",
    "\n",
    "print(\"=== BUSINESS IMPACT ANALYSIS ===\")\n",
    "print(f\"Current Model Accuracy (±15%): {current_accuracy:.1f}%\")\n",
    "print(f\"Business Target Accuracy: {target_accuracy:.1f}%\")\n",
    "print(f\"Improvement Needed: {improvement_needed:.1f} percentage points\")\n",
    "print(f\"Gap to Target: {(improvement_needed/target_accuracy*100):.1f}% relative improvement required\")\n",
    "\n",
    "# Calculate potential business impact\n",
    "total_equipment_value = df['SalePrice'].sum()\n",
    "annual_average_value = total_equipment_value / len(df['SaleYear'].unique())\n",
    "average_price = df['SalePrice'].mean()\n",
    "\n",
    "# Estimate pricing errors\n",
    "pricing_error_rate = (100 - current_accuracy) / 100\n",
    "potential_pricing_errors = annual_average_value * pricing_error_rate\n",
    "\n",
    "print(f\"\\n=== FINANCIAL IMPACT ===\")\n",
    "print(f\"Average Annual Equipment Value: ${annual_average_value:,.0f}\")\n",
    "print(f\"Average Equipment Price: ${average_price:,.0f}\")\n",
    "print(f\"Current Pricing Error Rate: {pricing_error_rate:.1%}\")\n",
    "print(f\"Annual Value at Risk: ${potential_pricing_errors:,.0f}\")\n",
    "\n",
    "# Risk assessment\n",
    "if current_accuracy < 50:\n",
    "    risk_level = \"CRITICAL\"\n",
    "    risk_color = \"#e74c3c\"\n",
    "elif current_accuracy < 70:\n",
    "    risk_level = \"HIGH\"\n",
    "    risk_color = \"#f39c12\"\n",
    "elif current_accuracy < 80:\n",
    "    risk_level = \"MEDIUM\"\n",
    "    risk_color = \"#f39c12\"\n",
    "else:\n",
    "    risk_level = \"LOW\"\n",
    "    risk_color = \"#2ecc71\"\n",
    "\n",
    "print(f\"\\n=== RISK ASSESSMENT ===\")\n",
    "print(f\"Current Risk Level: {risk_level}\")\n",
    "print(f\"Recommendation: {'IMMEDIATE IMPROVEMENT REQUIRED' if risk_level in ['CRITICAL', 'HIGH'] else 'PRODUCTION READY WITH MONITORING'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement Roadmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create improvement roadmap visualization\n",
    "improvement_stages = {\n",
    "    'Current State': {\n",
    "        'accuracy': current_accuracy,\n",
    "        'timeline': 0,\n",
    "        'actions': ['Basic RandomForest/CatBoost', 'Temporal validation', 'Standard features'],\n",
    "        'status': 'COMPLETE'\n",
    "    },\n",
    "    'Phase 1\\n(Month 1)': {\n",
    "        'accuracy': 55,\n",
    "        'timeline': 1,\n",
    "        'actions': ['Enhanced feature engineering', 'Usage data proxies', 'Geographic features'],\n",
    "        'status': 'PLANNED'\n",
    "    },\n",
    "    'Phase 2\\n(Month 2-3)': {\n",
    "        'accuracy': 65,\n",
    "        'timeline': 2.5,\n",
    "        'actions': ['Advanced models (XGBoost ensemble)', 'Market regime detection', 'Data quality improvements'],\n",
    "        'status': 'PLANNED'\n",
    "    },\n",
    "    'Phase 3\\n(Month 4-6)': {\n",
    "        'accuracy': 75,\n",
    "        'timeline': 5,\n",
    "        'actions': ['External data integration', 'Product-specific models', 'Advanced uncertainty quantification'],\n",
    "        'status': 'PLANNED'\n",
    "    },\n",
    "    'Target State\\n(Month 6+)': {\n",
    "        'accuracy': 80,\n",
    "        'timeline': 6,\n",
    "        'actions': ['Production deployment', 'Continuous monitoring', 'Human-in-loop validation'],\n",
    "        'status': 'TARGET'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Visualization\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 12))\n",
    "\n",
    "# Accuracy improvement timeline\n",
    "stages = list(improvement_stages.keys())\n",
    "timelines = [improvement_stages[stage]['timeline'] for stage in stages]\n",
    "accuracies = [improvement_stages[stage]['accuracy'] for stage in stages]\n",
    "statuses = [improvement_stages[stage]['status'] for stage in stages]\n",
    "\n",
    "colors = {'COMPLETE': '#2ecc71', 'PLANNED': '#3498db', 'TARGET': '#9b59b6'}\n",
    "stage_colors = [colors[status] for status in statuses]\n",
    "\n",
    "ax1.plot(timelines, accuracies, marker='o', linewidth=3, markersize=10, color='#34495e')\n",
    "ax1.scatter(timelines, accuracies, c=stage_colors, s=200, alpha=0.8, edgecolors='black', linewidth=2)\n",
    "ax1.axhline(y=target_accuracy, color='green', linestyle='--', linewidth=2, label=f'Business Target ({target_accuracy}%)')\n",
    "ax1.axhline(y=current_accuracy, color='red', linestyle='--', linewidth=2, alpha=0.7, label=f'Current State ({current_accuracy:.1f}%)')\n",
    "\n",
    "# Annotate points\n",
    "for i, (stage, timeline, accuracy) in enumerate(zip(stages, timelines, accuracies)):\n",
    "    ax1.annotate(f'{stage}\\n{accuracy:.0f}%', (timeline, accuracy), \n",
    "                xytext=(0, 20), textcoords='offset points', \n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor=stage_colors[i], alpha=0.7))\n",
    "\n",
    "ax1.set_xlabel('Timeline (Months)')\n",
    "ax1.set_ylabel('Model Accuracy within ±15% (%)')\n",
    "ax1.set_title('Model Improvement Roadmap', fontsize=16, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "ax1.set_ylim(35, 85)\n",
    "\n",
    "# Implementation phases breakdown\n",
    "phase_data = []\n",
    "for stage, details in improvement_stages.items():\n",
    "    for action in details['actions']:\n",
    "        phase_data.append({\n",
    "            'Stage': stage,\n",
    "            'Action': action,\n",
    "            'Target_Accuracy': details['accuracy'],\n",
    "            'Timeline': details['timeline'],\n",
    "            'Status': details['status']\n",
    "        })\n",
    "\n",
    "# Show key actions table\n",
    "ax2.axis('tight')\n",
    "ax2.axis('off')\n",
    "\n",
    "# Create table data\n",
    "table_data = []\n",
    "for stage, details in improvement_stages.items():\n",
    "    actions_str = '\\n'.join(details['actions'])\n",
    "    table_data.append([\n",
    "        stage.replace('\\n', ' '),\n",
    "        f\"{details['accuracy']:.0f}%\",\n",
    "        f\"{details['timeline']:.0f} months\",\n",
    "        actions_str,\n",
    "        details['status']\n",
    "    ])\n",
    "\n",
    "table = ax2.table(cellText=table_data,\n",
    "                 colLabels=['Phase', 'Target Accuracy', 'Timeline', 'Key Actions', 'Status'],\n",
    "                 cellLoc='left',\n",
    "                 loc='center',\n",
    "                 colWidths=[0.15, 0.12, 0.10, 0.48, 0.15])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1.2, 2)\n",
    "\n",
    "# Color code the table rows\n",
    "for i, status in enumerate([details['status'] for details in improvement_stages.values()]):\n",
    "    for j in range(5):\n",
    "        table[(i+1, j)].set_facecolor(colors[status])\n",
    "        table[(i+1, j)].set_alpha(0.3)\n",
    "\n",
    "ax2.set_title('Implementation Phases and Key Actions', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== IMPLEMENTATION PRIORITY ===\")\n",
    "print(\"1. IMMEDIATE (Month 1): Enhanced feature engineering - usage proxies, geographic features\")\n",
    "print(\"2. SHORT-TERM (Month 2-3): Advanced modeling and market regime detection\")\n",
    "print(\"3. MEDIUM-TERM (Month 4-6): External data integration and production deployment\")\n",
    "print(\"4. LONG-TERM (6+ months): Continuous improvement and human-in-loop validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Technical Implementation Details\n",
    "\n",
    "### Model Architecture and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technical implementation summary\n",
    "print(\"=== TECHNICAL ARCHITECTURE ===\")\n",
    "print(\"Model Type: Ensemble approach with RandomForest baseline and CatBoost primary\")\n",
    "print(\"Validation Strategy: Temporal splitting with comprehensive audit trail\")\n",
    "print(\"Data Leakage Protection: Removed future-looking features (log1p_price)\")\n",
    "print(\"Feature Engineering: Age, usage rates, geographic, temporal, and product hierarchy features\")\n",
    "\n",
    "print(\"\\n=== MODEL SPECIFICATIONS ===\")\n",
    "for model_name, model_data in model_results['models'].items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Sample Size: {model_data['sample_size']:,} records\")\n",
    "    print(f\"  Training Time: {model_data['training_time']:.1f} seconds\")\n",
    "    print(f\"  Model Path: {model_data['model_path']}\")\n",
    "    \n",
    "    test_metrics = model_data['test_metrics']\n",
    "    print(f\"  Test Performance:\")\n",
    "    print(f\"    - RMSLE: {test_metrics['rmsle']:.3f}\")\n",
    "    print(f\"    - MAE: ${test_metrics['mae']:,.0f}\")\n",
    "    print(f\"    - R²: {test_metrics['r2']:.3f}\")\n",
    "    print(f\"    - Within ±15%: {test_metrics['within_15_pct']:.1f}%\")\n",
    "\n",
    "print(\"\\n=== PRODUCTION READINESS ===\")\n",
    "print(\"✅ Temporal validation implemented\")\n",
    "print(\"✅ Data leakage prevention\")\n",
    "print(\"✅ Comprehensive error metrics\")\n",
    "print(\"✅ Model serialization and versioning\")\n",
    "print(\"❌ Business accuracy target not yet achieved\")\n",
    "print(\"❌ Requires feature engineering improvements\")\n",
    "print(\"❌ Needs additional data quality enhancements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk Mitigation Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk assessment and mitigation strategies\n",
    "risks = {\n",
    "    'Data Quality': {\n",
    "        'risk_level': 'HIGH',\n",
    "        'description': '82% missing usage data affects model accuracy',\n",
    "        'mitigation': 'Develop usage proxies using age, product type, and geographic patterns',\n",
    "        'timeline': '1 month'\n",
    "    },\n",
    "    'Market Volatility': {\n",
    "        'risk_level': 'HIGH', \n",
    "        'description': 'Model may fail during market downturns (2008-2010 pattern)',\n",
    "        'mitigation': 'Implement regime detection and market-aware model adjustments',\n",
    "        'timeline': '2-3 months'\n",
    "    },\n",
    "    'Model Performance': {\n",
    "        'risk_level': 'CRITICAL',\n",
    "        'description': 'Current 42.7% accuracy below 80% business target',\n",
    "        'mitigation': 'Enhanced feature engineering, ensemble methods, external data integration',\n",
    "        'timeline': '3-6 months'\n",
    "    },\n",
    "    'Geographic Bias': {\n",
    "        'risk_level': 'MEDIUM',\n",
    "        'description': '80% price variation across states may cause regional errors',\n",
    "        'mitigation': 'Include geographic features and regional validation',\n",
    "        'timeline': '1 month'\n",
    "    },\n",
    "    'Temporal Drift': {\n",
    "        'risk_level': 'MEDIUM',\n",
    "        'description': 'Model trained on 1989-2012 data may not reflect current market',\n",
    "        'mitigation': 'Continuous monitoring, periodic retraining, modern data integration',\n",
    "        'timeline': 'Ongoing'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create risk assessment visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Risk level distribution\n",
    "risk_levels = [risks[risk]['risk_level'] for risk in risks]\n",
    "risk_counts = pd.Series(risk_levels).value_counts()\n",
    "\n",
    "colors_risk = {'CRITICAL': '#e74c3c', 'HIGH': '#f39c12', 'MEDIUM': '#f1c40f', 'LOW': '#2ecc71'}\n",
    "pie_colors = [colors_risk[level] for level in risk_counts.index]\n",
    "\n",
    "ax1.pie(risk_counts.values, labels=risk_counts.index, autopct='%1.0f%%', \n",
    "        colors=pie_colors, startangle=90)\n",
    "ax1.set_title('Risk Level Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Risk mitigation timeline\n",
    "timeline_mapping = {\n",
    "    '1 month': 1,\n",
    "    '2-3 months': 2.5,\n",
    "    '3-6 months': 4.5,\n",
    "    'Ongoing': 6\n",
    "}\n",
    "\n",
    "risk_names = list(risks.keys())\n",
    "timelines = [timeline_mapping[risks[risk]['timeline']] for risk in risk_names]\n",
    "risk_colors = [colors_risk[risks[risk]['risk_level']] for risk in risk_names]\n",
    "\n",
    "bars = ax2.barh(risk_names, timelines, color=risk_colors, alpha=0.7)\n",
    "ax2.set_xlabel('Implementation Timeline (Months)')\n",
    "ax2.set_ylabel('Risk Category')\n",
    "ax2.set_title('Risk Mitigation Timeline', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add timeline labels\n",
    "for bar, timeline, risk in zip(bars, timelines, risk_names):\n",
    "    timeline_label = risks[risk]['timeline']\n",
    "    ax2.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2, \n",
    "             timeline_label, va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed risk assessment\n",
    "print(\"=== DETAILED RISK ASSESSMENT ===\")\n",
    "for risk_name, risk_data in risks.items():\n",
    "    print(f\"\\n{risk_name} - {risk_data['risk_level']} RISK\")\n",
    "    print(f\"  Description: {risk_data['description']}\")\n",
    "    print(f\"  Mitigation: {risk_data['mitigation']}\")\n",
    "    print(f\"  Timeline: {risk_data['timeline']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Executive Recommendations\n",
    "\n",
    "### Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executive summary and recommendations\n",
    "print(\"=== EXECUTIVE RECOMMENDATIONS ===\")\n",
    "print(\"\\n🎯 PRIMARY RECOMMENDATION: CONDITIONAL PROCEED WITH IMPROVEMENTS\")\n",
    "print(\"\\nThe current model provides a solid foundation but requires enhancement before production deployment.\")\n",
    "print(\"Current performance (42.7% within ±15%) falls short of the 80% business target.\")\n",
    "\n",
    "print(\"\\n📊 KEY PERFORMANCE METRICS:\")\n",
    "print(f\"  • Best Model: RandomForest\")\n",
    "print(f\"  • Current Accuracy: {current_accuracy:.1f}% within ±15% tolerance\")\n",
    "print(f\"  • RMSLE: {best_model_performance['RMSLE']:.3f}\")\n",
    "print(f\"  • R²: {best_model_performance['R²']:.3f}\")\n",
    "print(f\"  • Business Target: 80% within ±15%\")\n",
    "print(f\"  • Gap to Target: {improvement_needed:.1f} percentage points\")\n",
    "\n",
    "print(\"\\n🚀 IMMEDIATE ACTIONS (Next 30 Days):\")\n",
    "print(\"  1. Implement enhanced feature engineering for missing usage data\")\n",
    "print(\"  2. Develop geographic pricing adjustments\")\n",
    "print(\"  3. Create market volatility detection mechanisms\")\n",
    "print(\"  4. Establish continuous model monitoring framework\")\n",
    "\n",
    "print(\"\\n📈 SHORT-TERM GOALS (3-6 Months):\")\n",
    "print(f\"  • Target Accuracy: 65-75% within ±15%\")\n",
    "print(\"  • Enhanced model ensemble (XGBoost + CatBoost)\")\n",
    "print(\"  • External market data integration\")\n",
    "print(\"  • Production-ready deployment pipeline\")\n",
    "\n",
    "print(\"\\n💰 BUSINESS VALUE PROPOSITION:\")\n",
    "print(f\"  • Annual Equipment Value: ${annual_average_value:,.0f}\")\n",
    "print(f\"  • Current Risk Exposure: ${potential_pricing_errors:,.0f} annually\")\n",
    "print(\"  • Expected ROI: 15-25% improvement in pricing accuracy\")\n",
    "print(\"  • Competitive Advantage: Automated, consistent, and scalable pricing\")\n",
    "\n",
    "print(\"\\n⚠️ RISK MITIGATION:\")\n",
    "print(\"  • Phased deployment with human oversight\")\n",
    "print(\"  • Confidence intervals for all predictions\")\n",
    "print(\"  • Continuous performance monitoring\")\n",
    "print(\"  • Fallback to expert pricing for high-value items\")\n",
    "\n",
    "print(\"\\n✅ DECISION FRAMEWORK:\")\n",
    "print(\"  GO/NO-GO Criteria for Production:\")\n",
    "print(\"    ✅ Achieve >70% accuracy within ±15%\")\n",
    "print(\"    ✅ RMSLE < 0.25\")\n",
    "print(\"    ✅ Stable performance across geographic regions\")\n",
    "print(\"    ✅ Robust handling of market volatility\")\n",
    "    \n",
    "print(\"\\n📋 IMPLEMENTATION TIMELINE:\")\n",
    "timeline_summary = [\n",
    "    \"Month 1: Feature engineering improvements (+12% accuracy boost expected)\",\n",
    "    \"Month 2-3: Advanced modeling and ensemble methods (+10% accuracy boost)\",\n",
    "    \"Month 4-6: External data integration and production deployment (+8% accuracy boost)\",\n",
    "    \"Month 6+: Continuous improvement and optimization\"\n",
    "]\n",
    "\n",
    "for item in timeline_summary:\n",
    "    print(f\"  • {item}\")\n",
    "\n",
    "print(\"\\n🎯 SUCCESS METRICS:\")\n",
    "print(\"  • Primary: >80% predictions within ±15% of actual prices\")\n",
    "print(\"  • Secondary: RMSLE < 0.20, R² > 0.85\")\n",
    "print(\"  • Business: Reduced pricing disputes, faster quote generation\")\n",
    "print(\"  • Operational: <500ms prediction time, 99.9% system availability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "### Project Status and Final Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final project assessment\n",
    "print(\"=== FINAL PROJECT ASSESSMENT ===\")\n",
    "print(\"\\n📈 PROJECT STATUS: FOUNDATION ESTABLISHED - ENHANCEMENT REQUIRED\")\n",
    "\n",
    "print(\"\\n✅ ACHIEVEMENTS:\")\n",
    "achievements = [\n",
    "    \"Comprehensive data analysis identifying 5 critical business challenges\",\n",
    "    \"Robust temporal validation preventing data leakage\",\n",
    "    \"Production-ready model pipeline with RandomForest and CatBoost\",\n",
    "    \"Honest performance assessment with real business metrics\",\n",
    "    \"Professional visualization suite for stakeholder communication\",\n",
    "    \"Clear improvement roadmap with actionable next steps\"\n",
    "]\n",
    "\n",
    "for achievement in achievements:\n",
    "    print(f\"  • {achievement}\")\n",
    "\n",
    "print(\"\\n🎯 TECHNICAL QUALITY:\")\n",
    "print(f\"  • Model Performance: {best_model_performance['Within_15%']:.1f}% accuracy (Target: 80%)\")\n",
    "print(f\"  • Validation Strategy: Temporal splitting with audit trail\")\n",
    "print(f\"  • Data Quality: Comprehensive analysis of missing data and anomalies\")\n",
    "print(f\"  • Business Alignment: Clear ROI and risk assessment\")\n",
    "\n",
    "print(\"\\n📊 DELIVERABLES COMPLETED:\")\n",
    "deliverables = [\n",
    "    \"Master analysis notebook with real data and results\",\n",
    "    \"5 critical business findings with visualizations\",\n",
    "    \"Trained models (RandomForest: 42.7%, CatBoost: 42.5% within ±15%)\",\n",
    "    \"Comprehensive risk assessment and mitigation strategies\",\n",
    "    \"Implementation roadmap with 6-month timeline\",\n",
    "    \"Executive summary ready for stakeholder presentation\"\n",
    "]\n",
    "\n",
    "for deliverable in deliverables:\n",
    "    print(f\"  ✅ {deliverable}\")\n",
    "\n",
    "print(\"\\n🔮 FUTURE OUTLOOK:\")\n",
    "print(\"With targeted improvements, this solution can achieve production readiness within 3-6 months.\")\n",
    "print(\"The foundation is solid, the methodology is sound, and the path to success is clear.\")\n",
    "print(\"Expected final performance: 75-80% accuracy within ±15% tolerance.\")\n",
    "\n",
    "print(\"\\n📞 NEXT ENGAGEMENT:\")\n",
    "print(\"Ready for stakeholder review and approval to proceed with Phase 1 improvements.\")\n",
    "print(\"Recommended follow-up: Technical deep-dive session with ML engineering team.\")\n",
    "\n",
    "# Create final summary visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "# Progress towards business target\n",
    "current_progress = (current_accuracy / target_accuracy) * 100\n",
    "remaining_progress = 100 - current_progress\n",
    "\n",
    "progress_data = [current_progress, remaining_progress]\n",
    "progress_labels = [f'Achieved\\n{current_accuracy:.1f}%', f'Required\\n{target_accuracy - current_accuracy:.1f}%']\n",
    "progress_colors = ['#3498db', '#bdc3c7']\n",
    "\n",
    "# Create donut chart\n",
    "wedges, texts, autotexts = ax.pie(progress_data, labels=progress_labels, autopct='%1.1f%%', \n",
    "                                  colors=progress_colors, startangle=90, \n",
    "                                  wedgeprops=dict(width=0.5))\n",
    "\n",
    "# Add center text\n",
    "ax.text(0, 0, f'Progress to\\nBusiness Target\\n\\n{current_progress:.0f}%\\nComplete', \n",
    "        ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "ax.set_title('SHM Price Prediction Model: Progress to Business Target\\n(80% Accuracy within ±15%)', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SHM HEAVY EQUIPMENT PRICE PREDICTION\")\n",
    "print(\"Master Analysis Complete - Ready for Next Phase\")\n",
    "print(f\"Analysis Date: August 22, 2025\")\n",
    "print(f\"Model Performance: {current_accuracy:.1f}% within ±15% (RandomForest)\")\n",
    "print(f\"Business Assessment: Enhancement Required Before Production\")\n",
    "print(f\"Recommendation: Proceed with Phase 1 Improvements\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix: Technical Documentation\n",
    "\n",
    "### Model Files and Artifacts\n",
    "\n",
    "**Trained Models:**\n",
    "- `outputs/models/honest_randomforest_20250822_005248.joblib`\n",
    "- `outputs/models/honest_catboost_20250822_005248.joblib`\n",
    "\n",
    "**Performance Metrics:**\n",
    "- `outputs/models/honest_metrics_20250822_005248.json`\n",
    "\n",
    "**Business Findings:**\n",
    "- `outputs/findings/business_findings.json`\n",
    "- `outputs/findings/EXECUTIVE_SUMMARY.md`\n",
    "\n",
    "**Visualizations:**\n",
    "- `outputs/presentation/executive_dashboard.png`\n",
    "- `outputs/presentation/model_performance_suite.png`\n",
    "- `outputs/presentation/business_impact_analysis.png`\n",
    "\n",
    "### Contact Information\n",
    "\n",
    "**For Technical Questions:**\n",
    "- Model implementation and training details\n",
    "- Feature engineering and data preprocessing\n",
    "- Performance optimization and tuning\n",
    "\n",
    "**For Business Questions:**\n",
    "- ROI analysis and cost-benefit assessment\n",
    "- Implementation timeline and resource requirements\n",
    "- Risk management and mitigation strategies\n",
    "\n",
    "---\n",
    "\n",
    "*This analysis was conducted as part of the WeAreBit tech case assessment for SHM Heavy Equipment Price Prediction system development.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}